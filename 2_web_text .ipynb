{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia Extractor + cld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T00:32:23.025613Z",
     "start_time": "2019-05-16T00:32:22.952452Z"
    }
   },
   "outputs": [],
   "source": [
    "from xml.etree import cElementTree as ET\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    "import cld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T00:32:24.085970Z",
     "start_time": "2019-05-16T00:32:24.068980Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_func2(a):\n",
    "    split_a = re.split('; |, |\\. |\\n|! |:',a)\n",
    "    return split_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T00:32:24.485016Z",
     "start_time": "2019-05-16T00:32:24.385510Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_wolof_cld(file_dir):\n",
    "    with open(file_dir) as file:\n",
    "        data = file.read()\n",
    "    soup = BeautifulSoup(data)\n",
    "    text = soup.get_text()\n",
    "    alltext = text.split('\\n')\n",
    "    lines = [t for t in alltext if t is not '']\n",
    "    \n",
    "    # hey Evan maybe you can start from here. \n",
    "    wolof_utterance=[]\n",
    "    for item in lines:\n",
    "        isReliable, textBytesFound, details = cld2.detect(item)\n",
    "        if details[0][0]=='Unknown':\n",
    "            wolof_utterance.append(item.lstrip())\n",
    "            \n",
    "    c = []\n",
    "    for item in wolof_utterance:\n",
    "        c.append(split_func2(item))\n",
    "    space = ['', ' ']\n",
    "    utterance_all = [item for sublist in c for item in sublist if item not in space]\n",
    "    utterance_rm_digits = [re.sub(r\"\\b\\d+\\b\",\" \",item) for item in utterance_all]\n",
    "    utterance_rm_punc = [re.sub(r'[^\\w\\s]','',item) for item in utterance_rm_digits]  \n",
    "    utterance_rm_nspace = [' '.join(item.split()) for item in utterance_rm_punc]\n",
    "    utterance = [item for item in utterance_rm_nspace if len(item.split()) > 1]\n",
    "    \n",
    "    \n",
    "    wolof_utterance2=[]\n",
    "    for item in utterance:\n",
    "        isReliable, textBytesFound, details = cld2.detect(item)\n",
    "        if details[0][0]=='Unknown':\n",
    "            wolof_utterance2.append(item.lstrip())\n",
    "    \n",
    "    return wolof_utterance2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T00:32:26.998949Z",
     "start_time": "2019-05-16T00:32:25.432336Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki000 = clean_wolof_cld('text/AA/wiki_00.html')\n",
    "wiki001 = clean_wolof_cld('text/AA/wiki_01.html')\n",
    "wiki002 = clean_wolof_cld('text/AA/wiki_02.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T00:32:27.016001Z",
     "start_time": "2019-05-16T00:32:27.007249Z"
    }
   },
   "outputs": [],
   "source": [
    "wikinew = wiki000 + wiki001 + wiki002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T00:32:27.036119Z",
     "start_time": "2019-05-16T00:32:27.018577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nitñii motnañu', 66),\n",
       " ('atum g', 51),\n",
       " ('Ci atum gj', 19),\n",
       " ('ci geneen wàll', 18),\n",
       " ('Mu ne', 18),\n",
       " ('bokk na ci yooyu', 17),\n",
       " ('ngir waxam ja jm', 17),\n",
       " ('Ci làkku ibrë la tur wi jóge', 14),\n",
       " ('Sëñ bi nee na', 14),\n",
       " ('Kap Weer', 14)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(wikinew).most_common(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T19:31:49.667620Z",
     "start_time": "2019-05-15T19:31:49.552149Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('WIKI2019_2.txt', 'w') as f:\n",
    "    for item in wikinew:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
